print ("ds")
setwd("~/Projects/UdemyAtoZML/2_Regression/2.3_Polynomial_Regression")
dataset = read.csv('Position_Salaries.csv')
View(dataset)
View(dataset)
dataset = dataset[2:3]
View(dataset)
View(dataset)
lin_reg = lm(formula = Salary ~ .,
data = dataset)
summary(lin_reg)
lin_reg.coefficients
dataset$Level2 = dataset$Level^2
poly_reg = lm(formula = Salary ~ . ,
data = dataset)
summary(poly_reg)
summary(poly_reg)$coefficients
coef = summary(poly_reg)$coefficients
print(coef)
print(coef[2])
print(coef[2, 4])
coef(poly_reg)
coef(lin_reg)
coef(regressor)
"
Simple Linear Regression
"
#step 1: import the dataset
#set a working directory by going to the Files pane, find the correct folder, then go
#to More and click on "Set as Working Directory"
dataset = read.csv('Salary_Data.csv')
#dataset = dataset[, 2:3]
#Step 2: Splitting the dataset into the Training set and Test set
#install caTools library by install.packages('caTools')
#Then, check caTools in the Packages pane. OR use
library(caTools)
set.seed(123) #set seed so that every time we get the same random result
#sample.split() will randomly select specified percentage of tuples to be the training
#set and label them as TRUE. The test set tuples are labeled as FALSE
split = sample.split(dataset$Salary, SplitRatio = 2/3)
#create traning set and test set based on the TRUE and FALSE label created in the
#last step in dataset
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
#Feature scaling
# training_set[, 2:3] = scale(training_set[, 2:3])
# test_set[, 2:3] = scale(test_set[, 2:3])
#Step 3: Fit the simple linear regression to the Training set
#Salary ~ YearsExperience indicates the DV and the IV respectively
regressor = lm(formula = Salary ~ YearsExperience,
data = training_set
)
#show statistical results of the regressor
summary(regressor)
#show the coefficients of each terms in the model
coef(regressor)
#step 3: Fitting Polynomial Regression to the dataset
dataset$Level2 = dataset$Level^2
dataset$Level3 = dataset$Level^3
dataset$Level4 = dataset$Level^4
poly_reg = lm(formula = Salary ~ . ,
data = dataset)
summary(poly_reg)
#show the coefficients of each terms in the model
coef(poly_reg)
library("ggplot2", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.2")
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary), colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(lin_reg, newdata = dataset)), colour = 'blue') +
ggtitle('Truth or Bluff') +
xlab('Level') +
ylab('Salary')
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary), colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(lin_reg, newdata = dataset)), colour = 'blue') +
geom_line(aes(x = dataset$Level, y = predict(poly_reg, newdata = dataset)), colour = 'green') +
ggtitle('Truth or Bluff') +
xlab('Level') +
ylab('Salary')
predict(lin_reg, newdata = 6.5)
predict(poly_reg, newdata = 6.5)
predict(lin_reg, data.frame(Level = 6.5))
predict(poly_reg, data.frame(Level = 6.5))
y_lin_pred = predict(lin_reg, data.frame(Level = 6.5))
y_poly_pred = predict(poly_reg, data.frame(Level = 6.5))
#for polynomial model, we need to create a data frame to include all the terms in the model
y_poly_pred = predict(poly_reg, data.frame(Level = 6.5,
Level2 = 6.5^2,
Level3 = 6.5^3,
Level4 = 6.5^4))
